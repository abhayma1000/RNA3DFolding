{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f90aa192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T10:14:58.219698Z",
     "iopub.status.busy": "2025-02-28T10:14:58.219420Z",
     "iopub.status.idle": "2025-02-28T10:15:01.950899Z",
     "shell.execute_reply": "2025-02-28T10:15:01.950132Z"
    },
    "papermill": {
     "duration": 3.737002,
     "end_time": "2025-02-28T10:15:01.952585",
     "exception": false,
     "start_time": "2025-02-28T10:14:58.215583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beee4e4f",
   "metadata": {
    "papermill": {
     "duration": 0.003294,
     "end_time": "2025-02-28T10:15:01.959744",
     "exception": false,
     "start_time": "2025-02-28T10:15:01.956450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. CONFIG & SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19497539",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T10:15:01.967741Z",
     "iopub.status.busy": "2025-02-28T10:15:01.967320Z",
     "iopub.status.idle": "2025-02-28T10:15:01.976489Z",
     "shell.execute_reply": "2025-02-28T10:15:01.975672Z"
    },
    "papermill": {
     "duration": 0.014729,
     "end_time": "2025-02-28T10:15:01.977784",
     "exception": false,
     "start_time": "2025-02-28T10:15:01.963055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Set a random seed for Python, NumPy, PyTorch (CPU & GPU) to ensure reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Example configuration (you can load this from a YAML, JSON, etc.)\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"cutoff_date\": \"2020-01-01\",\n",
    "    \"test_cutoff_date\": \"2022-05-01\",\n",
    "    \"max_len\": 384,\n",
    "    \"batch_size\": 1,\n",
    "    \"model_config_path\": \"ribonanzanet2d-final/configs/pairwise.yaml\",\n",
    "    \"max_len_filter\": 9999999,\n",
    "    \"min_len_filter\": 10,\n",
    "    \n",
    "    \"ribonanzanet2d-final_path\": \"ribonanzanet2d-final\",\n",
    "    \"train_sequences_path\": \"stanford-rna-3d-folding/train_sequences.csv\",\n",
    "    \"train_labels_path\": \"stanford-rna-3d-folding/train_labels.csv\",\n",
    "    \"test_sequences_path\": \"stanford-rna-3d-folding/test_sequences.csv\",\n",
    "    \"pretrained_weights_path\": \"ribonanzanet-weights/RibonanzaNet.pt\",\n",
    "    \"save_weights_folder\": \"trained_model_weights\",\n",
    "    \"save_weights_name\": \"RibonanzaNet-3D.pt\",\n",
    "    \"save_weights_final\": \"RibonanzaNet-3D-final.pt\",\n",
    "}\n",
    "\n",
    "if not os.path.exists(config['save_weights_folder']):\n",
    "    os.mkdir(config['save_weights_folder'])\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "set_seed(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e896b07",
   "metadata": {
    "papermill": {
     "duration": 0.003166,
     "end_time": "2025-02-28T10:15:01.984333",
     "exception": false,
     "start_time": "2025-02-28T10:15:01.981167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. DATA LOADING & PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f8b580b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T10:15:01.992063Z",
     "iopub.status.busy": "2025-02-28T10:15:01.991802Z",
     "iopub.status.idle": "2025-02-28T10:15:10.866731Z",
     "shell.execute_reply": "2025-02-28T10:15:10.865637Z"
    },
    "papermill": {
     "duration": 8.880616,
     "end_time": "2025-02-28T10:15:10.868369",
     "exception": false,
     "start_time": "2025-02-28T10:15:01.987753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting XYZ data: 100%|██████████| 844/844 [00:05<00:00, 146.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load CSVs\n",
    "train_sequences = pd.read_csv(config[\"train_sequences_path\"])\n",
    "train_labels = pd.read_csv(config[\"train_labels_path\"])\n",
    "\n",
    "test_sequences = pd.read_csv(config[\"test_sequences_path\"])\n",
    "\n",
    "# Create a pdb_id field\n",
    "train_labels[\"pdb_id\"] = train_labels[\"ID\"].apply(\n",
    "    lambda x: x.split(\"_\")[0] + \"_\" + x.split(\"_\")[1]\n",
    ")\n",
    "\n",
    "# Collect xyz data for each sequence\n",
    "all_xyz = []\n",
    "for pdb_id in tqdm(train_sequences[\"target_id\"], desc=\"Collecting XYZ data\"):\n",
    "    df = train_labels[train_labels[\"pdb_id\"] == pdb_id]\n",
    "    xyz = df[[\"x_1\", \"y_1\", \"z_1\"]].to_numpy().astype(\"float32\")\n",
    "    xyz[xyz < -1e17] = float(\"nan\")\n",
    "    all_xyz.append(xyz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4e5bea",
   "metadata": {
    "papermill": {
     "duration": 0.006903,
     "end_time": "2025-02-28T10:15:10.883267",
     "exception": false,
     "start_time": "2025-02-28T10:15:10.876364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. DATA FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33f9760d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T10:15:10.898470Z",
     "iopub.status.busy": "2025-02-28T10:15:10.898184Z",
     "iopub.status.idle": "2025-02-28T10:15:10.914949Z",
     "shell.execute_reply": "2025-02-28T10:15:10.913938Z"
    },
    "papermill": {
     "duration": 0.025876,
     "end_time": "2025-02-28T10:15:10.916419",
     "exception": false,
     "start_time": "2025-02-28T10:15:10.890543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence in train: 4298\n"
     ]
    }
   ],
   "source": [
    "valid_indices = []\n",
    "max_len_seen = 0\n",
    "\n",
    "for i, xyz in enumerate(all_xyz):\n",
    "    # Track the maximum length\n",
    "    if len(xyz) > max_len_seen:\n",
    "        max_len_seen = len(xyz)\n",
    "\n",
    "    nan_ratio = np.isnan(xyz).mean()\n",
    "    seq_len = len(xyz)\n",
    "    # Keep sequence if it meets criteria\n",
    "    if (nan_ratio <= 0.5) and (config[\"min_len_filter\"] < seq_len < config[\"max_len_filter\"]):\n",
    "        valid_indices.append(i)\n",
    "\n",
    "print(f\"Longest sequence in train: {max_len_seen}\")\n",
    "\n",
    "# Filter sequences & xyz based on valid_indices\n",
    "train_sequences = train_sequences.loc[valid_indices].reset_index(drop=True)\n",
    "all_xyz = [all_xyz[i] for i in valid_indices]\n",
    "\n",
    "# Prepare final data dictionary\n",
    "data = {\n",
    "    \"sequence\": train_sequences[\"sequence\"].tolist(),\n",
    "    \"temporal_cutoff\": train_sequences[\"temporal_cutoff\"].tolist(),\n",
    "    \"description\": train_sequences[\"description\"].tolist(),\n",
    "    \"all_sequences\": train_sequences[\"all_sequences\"].tolist(),\n",
    "    \"xyz\": all_xyz,\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    \"sequence\": test_sequences[\"sequence\"].tolist(),\n",
    "    \"target_id\": test_sequences[\"target_id\"].tolist(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9957262a",
   "metadata": {
    "papermill": {
     "duration": 0.006847,
     "end_time": "2025-02-28T10:15:10.931112",
     "exception": false,
     "start_time": "2025-02-28T10:15:10.924265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. TRAIN / VAL SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d6e910a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T10:15:10.946619Z",
     "iopub.status.busy": "2025-02-28T10:15:10.946300Z",
     "iopub.status.idle": "2025-02-28T10:15:10.952769Z",
     "shell.execute_reply": "2025-02-28T10:15:10.951983Z"
    },
    "papermill": {
     "duration": 0.015688,
     "end_time": "2025-02-28T10:15:10.954128",
     "exception": false,
     "start_time": "2025-02-28T10:15:10.938440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cutoff_date = pd.Timestamp(config[\"cutoff_date\"])\n",
    "test_cutoff_date = pd.Timestamp(config[\"test_cutoff_date\"])\n",
    "\n",
    "train_indices = [i for i, date_str in enumerate(data[\"temporal_cutoff\"]) if pd.Timestamp(date_str) <= cutoff_date]\n",
    "val_indices = [i for i, date_str in enumerate(data[\"temporal_cutoff\"]) if cutoff_date < pd.Timestamp(date_str) <= test_cutoff_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c0c5d",
   "metadata": {
    "papermill": {
     "duration": 0.007268,
     "end_time": "2025-02-28T10:15:10.974877",
     "exception": false,
     "start_time": "2025-02-28T10:15:10.967609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. DATASET & DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1302fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T10:15:10.989372Z",
     "iopub.status.busy": "2025-02-28T10:15:10.989118Z",
     "iopub.status.idle": "2025-02-28T10:15:10.996099Z",
     "shell.execute_reply": "2025-02-28T10:15:10.995348Z"
    },
    "papermill": {
     "duration": 0.015863,
     "end_time": "2025-02-28T10:15:10.997556",
     "exception": false,
     "start_time": "2025-02-28T10:15:10.981693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNA3D_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for 3D RNA structures.\n",
    "    \"\"\"\n",
    "    def __init__(self, indices, data_dict, max_len=384):\n",
    "        self.indices = indices\n",
    "        self.data = data_dict\n",
    "        self.max_len = max_len\n",
    "        self.nt_to_idx = {nt: i for i, nt in enumerate(\"ACGU\")}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_idx = self.indices[idx]\n",
    "        # Convert nucleotides to integer tokens\n",
    "        sequence = [self.nt_to_idx[nt] for nt in self.data[\"sequence\"][data_idx]]\n",
    "        sequence = torch.tensor(sequence, dtype=torch.long)\n",
    "        # Convert xyz to torch tensor\n",
    "        xyz = torch.tensor(self.data[\"xyz\"][data_idx], dtype=torch.float32)\n",
    "\n",
    "        # If sequence is longer than max_len, randomly crop\n",
    "        if len(sequence) > self.max_len:\n",
    "            crop_start = np.random.randint(len(sequence) - self.max_len)\n",
    "            crop_end = crop_start + self.max_len\n",
    "            sequence = sequence[crop_start:crop_end]\n",
    "            xyz = xyz[crop_start:crop_end]\n",
    "\n",
    "        return {\"sequence\": sequence, \"xyz\": xyz}\n",
    "\n",
    "class RNA3D_Dataset_Test(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for 3D RNA structures.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dict, max_len=384):\n",
    "        self.data = data_dict\n",
    "        self.max_len = max_len\n",
    "        self.nt_to_idx = {nt: i for i, nt in enumerate(\"ACGU\")}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[\"sequence\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Convert nucleotides to integer tokens\n",
    "        sequence = [self.nt_to_idx[nt] if nt in self.nt_to_idx else 4 for nt in self.data[\"sequence\"][idx]]\n",
    "        sequence = torch.tensor(sequence, dtype=torch.long)\n",
    "        # Convert xyz to torch tensor\n",
    "\n",
    "        # Dont crop and return the full sequence\n",
    "\n",
    "        return {\"sequence\": sequence, \"target_id\": self.data[\"target_id\"][idx]}\n",
    "\n",
    "\n",
    "train_dataset = RNA3D_Dataset(train_indices, data, max_len=config[\"max_len\"])\n",
    "val_dataset = RNA3D_Dataset(val_indices, data, max_len=config[\"max_len\"])\n",
    "test_dataset = RNA3D_Dataset_Test(test_data, max_len=config[\"max_len\"])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6388efa6",
   "metadata": {
    "papermill": {
     "duration": 0.011346,
     "end_time": "2025-02-28T10:15:11.021895",
     "exception": false,
     "start_time": "2025-02-28T10:15:11.010549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. MODEL, CONFIG CLASSES & HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d295221b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T10:15:11.037253Z",
     "iopub.status.busy": "2025-02-28T10:15:11.036888Z",
     "iopub.status.idle": "2025-02-28T10:15:15.879530Z",
     "shell.execute_reply": "2025-02-28T10:15:15.878791Z"
    },
    "papermill": {
     "duration": 4.852189,
     "end_time": "2025-02-28T10:15:15.881166",
     "exception": false,
     "start_time": "2025-02-28T10:15:11.028977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing 9 ConvTransformerEncoderLayers\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(config[\"ribonanzanet2d-final_path\"])\n",
    "\n",
    "from Network import RibonanzaNet\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Simple Config class that can load from a dict or YAML.\"\"\"\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "        self.entries = entries\n",
    "\n",
    "    def print(self):\n",
    "        print(self.entries)\n",
    "\n",
    "def load_config_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        cfg = yaml.safe_load(file)\n",
    "    return Config(**cfg)\n",
    "\n",
    "class FinetunedRibonanzaNet(RibonanzaNet):\n",
    "    \"\"\"\n",
    "    A finetuned version of RibonanzaNet adapted for predicting 3D coordinates.\n",
    "    \"\"\"\n",
    "    def __init__(self, config_obj, pretrained=False, dropout=0.1):\n",
    "        # Modify config dropout before super init, if needed\n",
    "        config_obj.dropout = dropout\n",
    "        super(FinetunedRibonanzaNet, self).__init__(config_obj)\n",
    "\n",
    "        # Load pretrained weights if requested\n",
    "        if pretrained:\n",
    "            self.load_state_dict(\n",
    "                torch.load(config[\"pretrained_weights_path\"], map_location=\"cpu\")\n",
    "            )\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.xyz_predictor = nn.Linear(256, 3)\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"Forward pass to predict 3D XYZ coordinates.\"\"\"\n",
    "        # get_embeddings returns (sequence_features, *some_other_outputs)\n",
    "        sequence_features, _ = self.get_embeddings(\n",
    "            src, torch.ones_like(src).long().to(src.device)\n",
    "        )\n",
    "        xyz_pred = self.xyz_predictor(sequence_features)\n",
    "        return xyz_pred\n",
    "\n",
    "# Instantiate the model\n",
    "model_cfg = load_config_from_yaml(config[\"model_config_path\"])\n",
    "model = FinetunedRibonanzaNet(model_cfg, pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f295d511",
   "metadata": {
    "papermill": {
     "duration": 0.007205,
     "end_time": "2025-02-28T10:15:15.895806",
     "exception": false,
     "start_time": "2025-02-28T10:15:15.888601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. LOSS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "343c7934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T10:15:15.910919Z",
     "iopub.status.busy": "2025-02-28T10:15:15.910565Z",
     "iopub.status.idle": "2025-02-28T10:15:15.920617Z",
     "shell.execute_reply": "2025-02-28T10:15:15.920038Z"
    },
    "papermill": {
     "duration": 0.019053,
     "end_time": "2025-02-28T10:15:15.921825",
     "exception": false,
     "start_time": "2025-02-28T10:15:15.902772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(X, Y, epsilon=1e-4):\n",
    "    \"\"\"\n",
    "    Calculate pairwise distances between every point in X and every point in Y.\n",
    "    Shape: (len(X), len(Y))\n",
    "    \"\"\"\n",
    "    return ((X[:, None] - Y[None, :])**2 + epsilon).sum(dim=-1).sqrt()\n",
    "\n",
    "def dRMSD(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10, d_clamp=None):\n",
    "    \"\"\"\n",
    "    Distance-based RMSD.\n",
    "    pred_x, pred_y: predicted coordinates (usually the same tensor for X and Y).\n",
    "    gt_x, gt_y: ground truth coordinates.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = ~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff_sq = (pred_dm[mask] - gt_dm[mask])**2 + epsilon\n",
    "    if d_clamp is not None:\n",
    "        diff_sq = diff_sq.clamp(max=d_clamp**2)\n",
    "\n",
    "    return diff_sq.sqrt().mean() / Z\n",
    "\n",
    "def local_dRMSD(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10, d_clamp=30):\n",
    "    \"\"\"\n",
    "    Local distance-based RMSD, ignoring distances above a clamp threshold.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = (~torch.isnan(gt_dm)) & (gt_dm < d_clamp)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff_sq = (pred_dm[mask] - gt_dm[mask])**2 + epsilon\n",
    "    return diff_sq.sqrt().mean() / Z\n",
    "\n",
    "def dRMAE(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10):\n",
    "    \"\"\"\n",
    "    Distance-based Mean Absolute Error.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = ~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff = torch.abs(pred_dm[mask] - gt_dm[mask])\n",
    "    return diff.mean() / Z\n",
    "\n",
    "def align_svd_mae(input_coords, target_coords, Z=10):\n",
    "    \"\"\"\n",
    "    Align input_coords to target_coords via SVD (Kabsch algorithm) and compute MAE.\n",
    "    \"\"\"\n",
    "    assert input_coords.shape == target_coords.shape, \"Input and target must have the same shape\"\n",
    "\n",
    "    # Create mask for valid points\n",
    "    mask = ~torch.isnan(target_coords.sum(dim=-1))\n",
    "    input_coords = input_coords[mask]\n",
    "    target_coords = target_coords[mask]\n",
    "    \n",
    "    # Compute centroids\n",
    "    centroid_input = input_coords.mean(dim=0, keepdim=True)\n",
    "    centroid_target = target_coords.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # Center the points\n",
    "    input_centered = input_coords - centroid_input\n",
    "    target_centered = target_coords - centroid_target\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = input_centered.T @ target_centered\n",
    "\n",
    "    # SVD to find optimal rotation\n",
    "    U, S, Vt = torch.svd(cov_matrix)\n",
    "    R = Vt @ U.T\n",
    "\n",
    "    # Ensure a proper rotation (determinant R == 1)\n",
    "    if torch.det(R) < 0:\n",
    "        Vt_adj = Vt.clone()   # Clone to avoid in-place modification issues\n",
    "        Vt_adj[-1, :] = -Vt_adj[-1, :]\n",
    "        R = Vt_adj @ U.T\n",
    "\n",
    "    # Rotate input and compute mean absolute error\n",
    "    aligned_input = (input_centered @ R.T) + centroid_target\n",
    "    return torch.abs(aligned_input - target_coords).mean() / Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a91daf",
   "metadata": {
    "papermill": {
     "duration": 0.006713,
     "end_time": "2025-02-28T10:15:15.935655",
     "exception": false,
     "start_time": "2025-02-28T10:15:15.928942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8. TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b124051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T10:15:15.950251Z",
     "iopub.status.busy": "2025-02-28T10:15:15.950039Z",
     "iopub.status.idle": "2025-02-28T10:15:15.957741Z",
     "shell.execute_reply": "2025-02-28T10:15:15.957124Z"
    },
    "papermill": {
     "duration": 0.016374,
     "end_time": "2025-02-28T10:15:15.958920",
     "exception": false,
     "start_time": "2025-02-28T10:15:15.942546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_dl, val_dl, epochs=50, cos_epoch=35, lr=3e-4, clip=1):\n",
    "    \"\"\"Train the model with a CosineAnnealingLR after `cos_epoch` epochs.\"\"\"\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.0, lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=(epochs - cos_epoch) * len(train_dl),\n",
    "    )\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_preds = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_pbar = tqdm(train_dl, desc=f\"Training Epoch {epoch+1}/{epochs}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for idx, batch in enumerate(train_pbar):\n",
    "            sequence = batch[\"sequence\"].cuda()\n",
    "            gt_xyz = batch[\"xyz\"].squeeze().cuda()\n",
    "\n",
    "            pred_xyz = model(sequence).squeeze()\n",
    "\n",
    "            # Combine two distance-based losses\n",
    "            loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if (epoch + 1) > cos_epoch:\n",
    "                scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            avg_loss = running_loss / (idx + 1)\n",
    "            train_pbar.set_description(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        with torch.no_grad():\n",
    "            for idx, batch in enumerate(val_dl):\n",
    "                sequence = batch[\"sequence\"].cuda()\n",
    "                gt_xyz = batch[\"xyz\"].squeeze().cuda()\n",
    "\n",
    "                pred_xyz = model(sequence).squeeze()\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                val_preds.append((gt_xyz.cpu().numpy(), pred_xyz.cpu().numpy()))\n",
    "\n",
    "            val_loss /= len(val_dl)\n",
    "            print(f\"Validation Loss (Epoch {epoch+1}): {val_loss:.4f}\")\n",
    "\n",
    "            # Check for improvement\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_preds = val_preds\n",
    "                torch.save(model.state_dict(), os.path.join(config['save_weights_folder'], config[\"save_weights_name\"]))\n",
    "                print(f\"  -> New best model saved at epoch {epoch+1}\")\n",
    "\n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), os.path.join(config['save_weights_folder'], config[\"save_weights_final\"]))\n",
    "    return best_val_loss, best_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39df71",
   "metadata": {
    "papermill": {
     "duration": 0.006789,
     "end_time": "2025-02-28T10:15:15.972874",
     "exception": false,
     "start_time": "2025-02-28T10:15:15.966085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 9. RUN TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bb38825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T10:15:15.987854Z",
     "iopub.status.busy": "2025-02-28T10:15:15.987626Z",
     "iopub.status.idle": "2025-02-28T11:51:57.176994Z",
     "shell.execute_reply": "2025-02-28T11:51:57.176014Z"
    },
    "papermill": {
     "duration": 5803.801452,
     "end_time": "2025-02-28T11:51:59.781364",
     "exception": false,
     "start_time": "2025-02-28T10:15:15.979912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.7643: 100%|██████████| 542/542 [01:41<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss (Epoch 1): 2.2823\n",
      "  -> New best model saved at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 1.8087: 100%|██████████| 542/542 [01:48<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss (Epoch 2): 1.9316\n",
      "  -> New best model saved at epoch 2\n",
      "Best Validation Loss: 1.9316\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    best_loss, best_predictions = train_model(\n",
    "        model=model,\n",
    "        train_dl=train_loader,\n",
    "        val_dl=val_loader,\n",
    "        epochs=2,         # or config[\"epochs\"]\n",
    "        cos_epoch=1,      # or config[\"cos_epoch\"]\n",
    "        lr=3e-4,\n",
    "        clip=1\n",
    "    )\n",
    "    print(f\"Best Validation Loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276337d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd3023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "790a83ea",
   "metadata": {},
   "source": [
    "# 10. LOAD MODEL AND EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c063797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing 9 ConvTransformerEncoderLayers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = FinetunedRibonanzaNet(model_cfg, pretrained=True).cuda()\n",
    "loaded_model.load_state_dict(\n",
    "    torch.load(os.path.join(config['save_weights_folder'], config[\"save_weights_final\"]), map_location=\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba1fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Predictions: 100%|██████████| 12/12 [00:02<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>z_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>z_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>y_5</th>\n",
       "      <th>z_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1107_1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.248401</td>\n",
       "      <td>13.495464</td>\n",
       "      <td>7.266275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R1107_2</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>-13.397074</td>\n",
       "      <td>13.585758</td>\n",
       "      <td>7.623254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R1107_3</td>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>-13.304940</td>\n",
       "      <td>13.512511</td>\n",
       "      <td>7.322680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R1107_4</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>-13.239377</td>\n",
       "      <td>13.465967</td>\n",
       "      <td>7.145042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R1107_5</td>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>-13.109469</td>\n",
       "      <td>13.379914</td>\n",
       "      <td>6.821920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>R1190_114</td>\n",
       "      <td>U</td>\n",
       "      <td>114</td>\n",
       "      <td>-9.143088</td>\n",
       "      <td>8.074510</td>\n",
       "      <td>14.173927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>R1190_115</td>\n",
       "      <td>U</td>\n",
       "      <td>115</td>\n",
       "      <td>-0.772033</td>\n",
       "      <td>-0.794663</td>\n",
       "      <td>9.919549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>R1190_116</td>\n",
       "      <td>U</td>\n",
       "      <td>116</td>\n",
       "      <td>0.049683</td>\n",
       "      <td>-1.665415</td>\n",
       "      <td>9.272509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>R1190_117</td>\n",
       "      <td>U</td>\n",
       "      <td>117</td>\n",
       "      <td>1.107480</td>\n",
       "      <td>-2.759463</td>\n",
       "      <td>8.381992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>R1190_118</td>\n",
       "      <td>U</td>\n",
       "      <td>118</td>\n",
       "      <td>2.144652</td>\n",
       "      <td>-3.802996</td>\n",
       "      <td>7.447624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2515 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID resname resid        x_1        y_1        z_1  x_2  y_2  z_2  \\\n",
       "0       R1107_1       G     1 -13.248401  13.495464   7.266275  0.0  0.0  0.0   \n",
       "1       R1107_2       G     2 -13.397074  13.585758   7.623254  0.0  0.0  0.0   \n",
       "2       R1107_3       G     3 -13.304940  13.512511   7.322680  0.0  0.0  0.0   \n",
       "3       R1107_4       G     4 -13.239377  13.465967   7.145042  0.0  0.0  0.0   \n",
       "4       R1107_5       G     5 -13.109469  13.379914   6.821920  0.0  0.0  0.0   \n",
       "...         ...     ...   ...        ...        ...        ...  ...  ...  ...   \n",
       "2510  R1190_114       U   114  -9.143088   8.074510  14.173927  0.0  0.0  0.0   \n",
       "2511  R1190_115       U   115  -0.772033  -0.794663   9.919549  0.0  0.0  0.0   \n",
       "2512  R1190_116       U   116   0.049683  -1.665415   9.272509  0.0  0.0  0.0   \n",
       "2513  R1190_117       U   117   1.107480  -2.759463   8.381992  0.0  0.0  0.0   \n",
       "2514  R1190_118       U   118   2.144652  -3.802996   7.447624  0.0  0.0  0.0   \n",
       "\n",
       "      x_3  y_3  z_3  x_4  y_4  z_4  x_5  y_5  z_5  \n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "2510  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2511  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2512  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2513  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2514  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[2515 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_to_monomer = {i: nt for i, nt in enumerate(\"ACGU\")}\n",
    "def vals_to_monomers(val):\n",
    "    return [val_to_monomer[i] for i in val.tolist()]\n",
    "\n",
    "cols = [\"ID\",\"resname\",\"resid\",\"x_1\",\"y_1\",\"z_1\",\"x_2\",\"y_2\",\"z_2\",\"x_3\",\"y_3\",\"z_3\",\"x_4\",\"y_4\",\"z_4\",\"x_5\",\"y_5\",\"z_5\"]\n",
    "preds_pd = pd.DataFrame(columns=cols)\n",
    "\n",
    "with torch.no_grad():\n",
    "    loaded_model.eval()\n",
    "\n",
    "    test_pbar = tqdm(test_loader, desc=f\"Generating Predictions\")\n",
    "\n",
    "    test_preds = []\n",
    "    for idx, batch in enumerate(test_pbar):\n",
    "        sequence = batch[\"sequence\"].cuda()\n",
    "        res_names = vals_to_monomers(sequence.squeeze())\n",
    "        res_ids = [i + 1 for i in range(len(res_names))]\n",
    "        target_id = batch[\"target_id\"]\n",
    "\n",
    "\n",
    "        pred_xyz = loaded_model(sequence).squeeze().cpu().numpy()\n",
    "\n",
    "        new_row = {\n",
    "            \"ID\": [batch['target_id'][0] + \"_\" + str(i) for i in res_ids],\n",
    "            \"resname\": res_names,\n",
    "            \"resid\": res_ids,\n",
    "            \"x_1\": pred_xyz[:, 0],\n",
    "            \"y_1\": pred_xyz[:, 1],\n",
    "            \"z_1\": pred_xyz[:, 2],\n",
    "        }\n",
    "        for i in range(2, 6):\n",
    "            new_row[f\"x_{i}\"] = 0.0\n",
    "            new_row[f\"y_{i}\"] = 0.0\n",
    "            new_row[f\"z_{i}\"] = 0.0\n",
    "        \n",
    "        preds_pd = pd.concat([preds_pd, pd.DataFrame(new_row)], ignore_index=True)\n",
    "\n",
    "preds_pd.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Predictions saved to submission.csv\")\n",
    "\n",
    "display(preds_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91741bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11228175,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 4299272,
     "sourceId": 7639698,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4459124,
     "sourceId": 8318191,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5832.807833,
   "end_time": "2025-02-28T11:52:04.178236",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-28T10:14:51.370403",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
