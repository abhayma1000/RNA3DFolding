{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Purpose\n",
    "\n",
    "Understand the data, plot the thingies out and see what they look like. Maybe find some interesting things to know that I can use when I make the model\n",
    "\n",
    "# What I want to do here\n",
    "\n",
    "[x] Plot different structures. Plot from low size to high size and in between\n",
    "[x] Plot every structure\n",
    "\n",
    "[x] Different values in /nan/null/other in the data\n",
    "\n",
    "\n",
    "[x] See the distribution of lengths of polymers\n",
    "[x] See the distribution of different nucelotides\n",
    "[x] See what distribution of nucleotides in what part of the string\n",
    "[x] Most common k-length sequences\n",
    "\n",
    "[x] See the distribution of distances between the different points\n",
    "[x] See the distribution in change of angle between the different points\n",
    "\n",
    "\n",
    "[x] Plot the densitities of the models\n",
    "\n",
    "\n",
    "[x] Plot the cutoff dates\n",
    "\n",
    "\n",
    "* Investigate the description, find common words, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import general_utils\n",
    "import utils\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.stats import gaussian_kde\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "import GPUtil\n",
    "\n",
    "GPUs = GPUtil.getGPUs()\n",
    "if GPUs:\n",
    "    gpu = GPUs[0]\n",
    "    print(f\"Running on: {gpu.name}\")\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Set a random seed for Python, NumPy, PyTorch (CPU & GPU) to ensure reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Example configuration (you can load this from a YAML, JSON, etc.)\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"cutoff_date\": \"2020-01-01\",\n",
    "    \"test_cutoff_date\": \"2022-05-01\",\n",
    "    \"max_len\": 384,\n",
    "    \"batch_size\": 1,\n",
    "\n",
    "    \"max_len_filter\": 9999999,\n",
    "    \"min_len_filter\": 10,\n",
    "    \n",
    "    # change to kaggle\n",
    "    \"train_sequences_path\": \"stanford-rna-3d-folding/train_sequences.csv\",\n",
    "    \"train_labels_path\": \"stanford-rna-3d-folding/train_labels.csv\",\n",
    "    \"test_sequences_path\": \"stanford-rna-3d-folding/test_sequences.csv\",\n",
    "}\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "set_seed(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(config[\"train_labels_path\"])\n",
    "\n",
    "train_sequences = pd.read_csv(config[\"train_sequences_path\"])\n",
    "\n",
    "train_labels['target_id'] = train_labels['ID'].apply(lambda x: x.split('_')[0] + '_' + x.split('_')[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot structures\n",
    "\n",
    "Plot from small to big and in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ranks_wanted = [1, 2, 5, 10, 15, 20, 99, 100]\n",
    "max_len = train_sequences['sequence'].apply(lambda x: len(x)).max()\n",
    "ranks_wanted = [int(max_len * (rank / 100.)) for rank in ranks_wanted]\n",
    "\n",
    "train_sequences['length'] = train_sequences['sequence'].apply(lambda x: len(x))\n",
    "train_sequences['length_ranking'] = train_sequences['length'].rank()\n",
    "\n",
    "\n",
    "for i, rank in enumerate(ranks_wanted):\n",
    "    random_val = np.random.randint(1, 3)\n",
    "\n",
    "    target_id = train_sequences.iloc[(train_sequences['length_ranking'] - rank).abs().argsort()[random_val - 1:random_val]]['target_id'].values[0]\n",
    "    \n",
    "    sequence = np.array(list(train_sequences[train_sequences['target_id'] == target_id]['sequence'].values[0]))\n",
    "\n",
    "    x_1 = train_labels[train_labels['target_id'] == target_id]['x_1'].to_numpy()\n",
    "    y_1 = train_labels[train_labels['target_id'] == target_id]['y_1'].to_numpy()\n",
    "    z_1 = train_labels[train_labels['target_id'] == target_id]['z_1'].to_numpy()\n",
    "\n",
    "    utils.plot_structure(\n",
    "        sequences=sequence,\n",
    "        x=x_1,\n",
    "        y=y_1,\n",
    "        z=z_1,\n",
    "        name=target_id,\n",
    "        size=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot every RNA together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = train_labels['target_id'].unique()\n",
    "\n",
    "all_data_entries = []\n",
    "\n",
    "for i, target_id in enumerate(all_ids):\n",
    "    sequence = np.array(list(train_sequences[train_sequences['target_id'] == target_id]['sequence'].values[0]))\n",
    "\n",
    "    x_1 = train_labels[train_labels['target_id'] == target_id]['x_1'].to_numpy()\n",
    "    y_1 = train_labels[train_labels['target_id'] == target_id]['y_1'].to_numpy()\n",
    "    z_1 = train_labels[train_labels['target_id'] == target_id]['z_1'].to_numpy()\n",
    "\n",
    "    all_data_entries.append(\n",
    "        {\n",
    "            'name': target_id,\n",
    "            'sequences': sequence,\n",
    "            'x': x_1,\n",
    "            'y': y_1,\n",
    "            'z': z_1\n",
    "        }\n",
    "    )\n",
    "\n",
    "utils.plot_multiple_structures(all_data_entries, size=2, linewidth=0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore null/nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows_count = train_labels[['x_1', 'y_1', 'z_1']].isnull().any(axis=1).sum()\n",
    "print(f\"Number of rows with null values in coordinates: {null_rows_count}\")\n",
    "print(f\"Percentage of rows with null values in coordinates: {null_rows_count / len(train_labels) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleotides = set(''.join(train_sequences['sequence'].values))\n",
    "print(f\"Unique nucleotides in train_sequences: {nucleotides}\")\n",
    "\n",
    "print(f\"Unique nucleotides in train_labels: {list(train_labels['resname'].unique())}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nucleotide in nucleotides:\n",
    "    print(f\"Number of {nucleotide} in train_sequences: {train_sequences['sequence'].str.count(nucleotide).sum()}\")\n",
    "\n",
    "    print(f\"Percentage of {nucleotide} in train_sequences: {train_sequences['sequence'].str.count(nucleotide).sum() / train_sequences['sequence'].apply(lambda x: len(x)).sum() * 100.:.2f}%\")\n",
    "\n",
    "    print(f\"Number of null values in location with {nucleotide} nucleotide: {train_labels[train_labels['resname'] == nucleotide]['x_1'].isnull().sum()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot distribution of xyz coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values for x_1, y_1, and z_1\n",
    "coordinates = ['x_1', 'y_1', 'z_1']\n",
    "values = {coord: train_labels[coord].dropna() for coord in coordinates}\n",
    "\n",
    "# Define bins for the ranges\n",
    "bins = {coord: np.linspace(values[coord].min(), values[coord].max(), 20) for coord in coordinates}\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "# Plot histograms\n",
    "for i, coord in enumerate(coordinates):\n",
    "    axes[i].hist(values[coord], bins=bins[coord], edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_title(f'Frequency of {coord} Ranges')\n",
    "    axes[i].set_xlabel(f'{coord} Range')\n",
    "    axes[i].set_ylabel('Frequency' if i == 0 else '')\n",
    "    axes[i].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of RNA length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences['sequence'].apply(lambda x: len(x)).plot.hist(\n",
    "    bins=100,\n",
    "    title='Length of Sequences Frequency Distribution',\n",
    "    xlabel='Length',\n",
    "    ylabel='Frequency',\n",
    "    figsize=(10, 6),\n",
    "    grid=True,\n",
    "    color='blue',\n",
    "    alpha=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What nucleotides in what segment of a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_nucleotides = ['A', 'C', 'G', 'U']\n",
    "\n",
    "k=5 # number of parts to split the sequence into\n",
    "ratios_dict = {}\n",
    "\n",
    "for nucleotide in useful_nucleotides:\n",
    "    for i in range(k):\n",
    "        num_that = train_sequences['sequence'].apply(lambda x: x[int(i / k * len(x)):int((i + 1) / k * len(x))]).str.count(nucleotide)\n",
    "        len_that = train_sequences['sequence'].apply(lambda x: len(x[int(i / k * len(x)):int((i + 1) / k * len(x))]))\n",
    "        ratio = num_that / len_that\n",
    "        key = f\"{nucleotide}_{i + 1}\"\n",
    "        ratios_dict[key] = ratio.mean()\n",
    "        print(f\"Ratio of {nucleotide} in {i + 1}th part of sequence: {ratio.mean() * 100.:.2f}%\")\n",
    "\n",
    "ratios_df = pd.DataFrame(list(ratios_dict.items()), columns=['Segment', 'Mean Ratio'])\n",
    "\n",
    "\n",
    "ratios_df[['Nucleotide', 'Part']] = ratios_df['Segment'].str.split('_', expand=True)\n",
    "ratios_df['Part'] = ratios_df['Part'].astype(int)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for nucleotide in useful_nucleotides:\n",
    "    subset = ratios_df[ratios_df['Nucleotide'] == nucleotide]\n",
    "    plt.plot(subset['Part'], subset['Mean Ratio'], marker='o', label=nucleotide)\n",
    "\n",
    "plt.title('Mean Ratio of Nucleotides in Different Parts of Sequences')\n",
    "plt.xlabel(f'Part of Sequence (split into {k} parts)')\n",
    "plt.ylabel('Mean Ratio')\n",
    "plt.legend(title='Nucleotide')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find common k-length sequences\n",
    "\n",
    "Uses sliding window on all sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "all_sequences = train_sequences['sequence'].to_list()\n",
    "\n",
    "k_sequences = {}\n",
    "\n",
    "for sequence in all_sequences:\n",
    "    for i in range(len(sequence) - k + 1):\n",
    "        if sequence[i:i + k] in k_sequences.keys():\n",
    "            k_sequences[sequence[i:i + k]] += 1\n",
    "        else:\n",
    "            k_sequences[sequence[i:i + k]] = 1\n",
    "\n",
    "num_most_popular = 5\n",
    "\n",
    "# get the ten most popular k-sequences\n",
    "most_popular_k_sequences = sorted(k_sequences.items(), key=lambda x: x[1], reverse=True)[:num_most_popular]\n",
    "print(f\"The {num_most_popular} most popular {k} length k-sequences are: \", most_popular_k_sequences)\n",
    "\n",
    "all_sequences_length = len(''.join(all_sequences))\n",
    "\n",
    "for i in most_popular_k_sequences:\n",
    "    print(f\"Ratio of {i[0]} in all {k}-length sequences: {i[1] / all_sequences_length * 100.:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the distribution of distances between consecutive points for each dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distances = None\n",
    "\n",
    "for id in all_ids:\n",
    "    this_labels = train_labels[train_labels['target_id'] == id]\n",
    "    \n",
    "    distances = this_labels[['x_1', 'y_1', 'z_1']].dropna().to_numpy()\n",
    "    distances = np.diff(distances, axis=0)\n",
    "\n",
    "    if all_distances is None:\n",
    "        all_distances = distances\n",
    "    else:\n",
    "        all_distances = np.vstack((all_distances, distances))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "for i in range(3):\n",
    "    axs[i].hist(distances[:, i], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axs[i].set_title('Distances')\n",
    "    axs[i].set_xlabel('Distance')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "    axs[i].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the distribution of change in angle between consecutive points\n",
    "\n",
    "TODO Ensure correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_change_3d(p1: np.array, p2: np.array, p3: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Computes change in angle from p1 to p2 vs p3 in 3d space\n",
    "    \"\"\"\n",
    "\n",
    "    v1 = p2 - p1\n",
    "    v2 = p3 - p2\n",
    "    \n",
    "    v1_norm = np.linalg.norm(v1)\n",
    "    v2_norm = np.linalg.norm(v2)\n",
    "    \n",
    "    if v1_norm == 0 or v2_norm == 0:\n",
    "        raise ValueError(\"One of the vectors has zero length, cannot compute angle.\")\n",
    "    \n",
    "    v1 = v1 / v1_norm\n",
    "    v2 = v2 / v2_norm\n",
    "\n",
    "    dot_product = np.clip(np.dot(v1, v2), -1.0, 1.0)\n",
    "    \n",
    "    return np.degrees(np.arccos(dot_product))\n",
    "\n",
    "xyz_cats = ['x_1', 'y_1', 'z_1']\n",
    "\n",
    "all_xyz = train_labels[xyz_cats].dropna().to_numpy()\n",
    "\n",
    "print(all_xyz.shape)\n",
    "\n",
    "differences = np.empty((all_xyz.shape[0] - 2, 3))\n",
    "\n",
    "for i in range(len(all_xyz) - 2 - 1):\n",
    "    differences[i, :] = angle_change_3d(all_xyz[i], all_xyz[i + 1], all_xyz[i + 2])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    axs[i].hist(differences[:, i], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axs[i].set_title(f'{xyz_cats[i]}-axis Delta Angles')\n",
    "    axs[i].set_xlabel('Angle (degrees)')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "    axs[i].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the densities of different models\n",
    "\n",
    "See if the small sequences are more dense than the big sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = []\n",
    "densities = []\n",
    "cutoff_threshold = 3 # If less than 3 points, ignore\n",
    "\n",
    "for i, id in enumerate(all_ids):\n",
    "    this_labels = train_labels[train_labels['target_id'] == id]\n",
    "\n",
    "    all_points = this_labels[['x_1', 'y_1', 'z_1']].dropna().to_numpy()\n",
    "\n",
    "    if all_points.shape[0] > cutoff_threshold:\n",
    "        center_point = np.mean(all_points, axis=0)\n",
    "        kde = gaussian_kde(all_points.T)\n",
    "\n",
    "        sizes.append(all_points.shape[0])\n",
    "\n",
    "        densities.append(kde(center_point))\n",
    "\n",
    "\n",
    "plt.scatter(np.array(sizes), np.array(densities))\n",
    "plt.title('Density vs. Sequence Size')\n",
    "plt.xlabel('Sequence Size')\n",
    "plt.ylabel('Density')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, which='both', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the temporal cutoff points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date_nums = pd.to_datetime(train_sequences['temporal_cutoff']).map(pd.Timestamp.toordinal).values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "ax.boxplot(date_nums, vert=False)\n",
    "\n",
    "# Convert ordinal numbers back to readable dates for axis labels\n",
    "ax.set_xticks(np.linspace(min(date_nums), max(date_nums), num=5))\n",
    "ax.set_xticklabels(pd.to_datetime([pd.Timestamp.fromordinal(int(t)) for t in np.linspace(min(date_nums), max(date_nums), num=5)]).strftime('%Y-%m-%d'))\n",
    "\n",
    "ax.set_title(\"Boxplot of Temporal cutoff Dates\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot frequencies of different words in description\n",
    "\n",
    "Actually, this was pretty useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "num_top_words = 10\n",
    "\n",
    "counters_found = Counter(' '.join(train_sequences['description'].astype(object).values).split(' '))\n",
    "\n",
    "counters_found = dict(counters_found)\n",
    "\n",
    "counters_found = {k: v for k, v in sorted(counters_found.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "sns.boxplot(y=list(counters_found.keys())[:num_top_words], x=list(counters_found.values())[:num_top_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = {}\n",
    "\n",
    "def count_chain_types(the_str: str):\n",
    "    first_occurance_index = the_str.index(\"|\")\n",
    "    second = the_str[first_occurance_index + 1:].find(\"[\")\n",
    "    if second == -1:\n",
    "        second = float(\"inf\")\n",
    "    end_index = min(the_str[first_occurance_index + 1:].index(\"|\"), second)\n",
    "    new_substring = the_str[first_occurance_index + 2:first_occurance_index + 1 + end_index] # +2 to skip the first \"|\" and the \"C\" from \"Chain\"\n",
    "    for i, char in enumerate(new_substring):\n",
    "        if char.isupper():\n",
    "            if char in chains.keys():\n",
    "                chains[char] += 1\n",
    "            else:\n",
    "                chains[char] = 1\n",
    "    \n",
    "\n",
    "obj_all_sequences = train_sequences['all_sequences'].astype(object).dropna()\n",
    "normal_all_sequences = obj_all_sequences[obj_all_sequences.str.len() > 5]\n",
    "\n",
    "\n",
    "total_entries = len(normal_all_sequences.values)\n",
    "print(\"Total entries in all_sequences: \", total_entries)\n",
    "\n",
    "normal_all_sequences.apply(lambda x: count_chain_types(x) if type(x) == str else None)\n",
    "chains_sorted = sorted(chains.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "for i in chains_sorted:\n",
    "    print(f\"Chain {i[0]}: {i[1]} occurances. Ratio: {i[1] / total_entries * 100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar([i[0] for i in chains_sorted], [i[1] for i in chains_sorted])\n",
    "plt.title('Frequency of Different Chains')\n",
    "plt.xlabel('Chain Type')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_labels.head(3))\n",
    "display(train_sequences.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Fasta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fasta(file_path):\n",
    "    \"\"\"\n",
    "    Displays the contents of a FASTA file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the FASTA file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                print(line, end='')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "# file_path = 'sequence.fasta'\n",
    "# display_fasta(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'stanford-rna-3d-folding/MSA/{all_ids[0]}.MSA.fasta'\n",
    "display_fasta(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
