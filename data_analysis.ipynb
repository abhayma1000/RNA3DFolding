{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "Understand the data, plot the thingies out and see what they look like. Maybe find some interesting things to know that I can use when I make the model\n",
    "\n",
    "# What I want to do here\n",
    "\n",
    "[x] Plot different structures. Plot from low size to high size and in between\n",
    "[x] Plot every structure\n",
    "\n",
    "[x] Different values in /nan/null/other in the data\n",
    "\n",
    "\n",
    "[x] See the distribution of lengths of polymers\n",
    "[x] See the distribution of different nucelotides\n",
    "[x] See what distribution of nucleotides in what part of the string\n",
    "[INPROG] Most common k-length sequences\n",
    "\n",
    "[INPROG] See the distribution of distances between the different points\n",
    "[INPROG] See the distribution in change of angle between the different points\n",
    "\n",
    "\n",
    "* Plot the densitities of the models\n",
    "\n",
    "\n",
    "* Plot the cutoff dates\n",
    "\n",
    "\n",
    "* Investigate the description, find common words, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import general_utils\n",
    "import utils\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "import GPUtil\n",
    "\n",
    "GPUs = GPUtil.getGPUs()\n",
    "if GPUs:\n",
    "    gpu = GPUs[0]\n",
    "    print(f\"Running on: {gpu.name}\")\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Set a random seed for Python, NumPy, PyTorch (CPU & GPU) to ensure reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Example configuration (you can load this from a YAML, JSON, etc.)\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"cutoff_date\": \"2020-01-01\",\n",
    "    \"test_cutoff_date\": \"2022-05-01\",\n",
    "    \"max_len\": 384,\n",
    "    \"batch_size\": 1,\n",
    "\n",
    "    \"max_len_filter\": 9999999,\n",
    "    \"min_len_filter\": 10,\n",
    "    \n",
    "    # change to kaggle\n",
    "    \"train_sequences_path\": \"stanford-rna-3d-folding/train_sequences.csv\",\n",
    "    \"train_labels_path\": \"stanford-rna-3d-folding/train_labels.csv\",\n",
    "    \"test_sequences_path\": \"stanford-rna-3d-folding/test_sequences.csv\",\n",
    "}\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "set_seed(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(config[\"train_labels_path\"])\n",
    "\n",
    "train_sequences = pd.read_csv(config[\"train_sequences_path\"])\n",
    "\n",
    "train_labels['target_id'] = train_labels['ID'].apply(lambda x: x.split('_')[0] + '_' + x.split('_')[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot structures\n",
    "\n",
    "Plot from small to big and in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ranks_wanted = [1, 2, 5, 10, 25, 35, 50, 75, 90, 99, 100]\n",
    "max_len = train_sequences['sequence'].apply(lambda x: len(x)).max()\n",
    "ranks_wanted = [int(max_len * (rank / 100.)) for rank in ranks_wanted]\n",
    "\n",
    "train_sequences['length'] = train_sequences['sequence'].apply(lambda x: len(x))\n",
    "train_sequences['length_ranking'] = train_sequences['length'].rank()\n",
    "\n",
    "\n",
    "for i, rank in enumerate(ranks_wanted):\n",
    "    random_val = np.random.randint(1, 3)\n",
    "\n",
    "    target_id = train_sequences.iloc[(train_sequences['length_ranking'] - rank).abs().argsort()[random_val - 1:random_val]]['target_id'].values[0]\n",
    "    \n",
    "    sequence = np.array(list(train_sequences[train_sequences['target_id'] == target_id]['sequence'].values[0]))\n",
    "\n",
    "    x_1 = train_labels[train_labels['target_id'] == target_id]['x_1'].to_numpy()\n",
    "    y_1 = train_labels[train_labels['target_id'] == target_id]['y_1'].to_numpy()\n",
    "    z_1 = train_labels[train_labels['target_id'] == target_id]['z_1'].to_numpy()\n",
    "\n",
    "    utils.plot_structure(\n",
    "        sequences=sequence,\n",
    "        x=x_1,\n",
    "        y=y_1,\n",
    "        z=z_1,\n",
    "        name=target_id,\n",
    "        size=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot every RNA together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = train_labels['target_id'].unique()\n",
    "\n",
    "all_data_entries = []\n",
    "\n",
    "for i, target_id in enumerate(all_ids):\n",
    "    sequence = np.array(list(train_sequences[train_sequences['target_id'] == target_id]['sequence'].values[0]))\n",
    "\n",
    "    x_1 = train_labels[train_labels['target_id'] == target_id]['x_1'].to_numpy()\n",
    "    y_1 = train_labels[train_labels['target_id'] == target_id]['y_1'].to_numpy()\n",
    "    z_1 = train_labels[train_labels['target_id'] == target_id]['z_1'].to_numpy()\n",
    "\n",
    "    all_data_entries.append(\n",
    "        {\n",
    "            'name': target_id,\n",
    "            'sequences': sequence,\n",
    "            'x': x_1,\n",
    "            'y': y_1,\n",
    "            'z': z_1\n",
    "        }\n",
    "    )\n",
    "\n",
    "utils.plot_multiple_structures(all_data_entries, size=2, linewidth=0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore null/nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows_count = train_labels[['x_1', 'y_1', 'z_1']].isnull().any(axis=1).sum()\n",
    "print(f\"Number of rows with null values in coordinates: {null_rows_count}\")\n",
    "print(f\"Percentage of rows with null values in coordinates: {null_rows_count / len(train_labels) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleotides = set(''.join(train_sequences['sequence'].values))\n",
    "print(f\"Unique nucleotides in train_sequences: {nucleotides}\")\n",
    "\n",
    "print(f\"Unique nucleotides in train_labels: {list(train_labels['resname'].unique())}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nucleotide in nucleotides:\n",
    "    print(f\"Number of {nucleotide} in train_sequences: {train_sequences['sequence'].str.count(nucleotide).sum()}\")\n",
    "\n",
    "    print(f\"Percentage of {nucleotide} in train_sequences: {train_sequences['sequence'].str.count(nucleotide).sum() / len(train_sequences) * 100.:.2f}%\")\n",
    "\n",
    "    print(f\"Number of null values in location with {nucleotide} nucleotide: {train_labels[train_labels['resname'] == nucleotide]['x_1'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot distribution of xyz coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values for x_1, y_1, and z_1\n",
    "coordinates = ['x_1', 'y_1', 'z_1']\n",
    "values = {coord: train_labels[coord].dropna() for coord in coordinates}\n",
    "\n",
    "# Define bins for the ranges\n",
    "bins = {coord: np.linspace(values[coord].min(), values[coord].max(), 20) for coord in coordinates}\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "# Plot histograms\n",
    "for i, coord in enumerate(coordinates):\n",
    "    axes[i].hist(values[coord], bins=bins[coord], edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_title(f'Frequency of {coord} Ranges')\n",
    "    axes[i].set_xlabel(f'{coord} Range')\n",
    "    axes[i].set_ylabel('Frequency' if i == 0 else '')\n",
    "    axes[i].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of RNA length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences['sequence'].apply(lambda x: len(x)).plot.hist(\n",
    "    bins=100,\n",
    "    title='Length of Sequences Frequency Distribution',\n",
    "    xlabel='Length',\n",
    "    ylabel='Frequency',\n",
    "    figsize=(10, 6),\n",
    "    grid=True,\n",
    "    color='blue',\n",
    "    alpha=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What nucleotides in what segment of a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_nucleotides = ['A', 'C', 'G', 'U']\n",
    "\n",
    "k=5\n",
    "ratios_dict = {}\n",
    "\n",
    "for nucleotide in useful_nucleotides:\n",
    "    for i in range(k):\n",
    "        num_that = train_sequences['sequence'].apply(lambda x: x[int(i / k * len(x)):int((i + 1) / k * len(x))]).str.count(nucleotide)\n",
    "        len_that = train_sequences['sequence'].apply(lambda x: len(x[int(i / k * len(x)):int((i + 1) / k * len(x))]))\n",
    "        ratio = num_that / len_that\n",
    "        key = f\"{nucleotide}_{i + 1}\"\n",
    "        ratios_dict[key] = ratio.mean()\n",
    "        print(f\"Ratio of {nucleotide} in {i + 1}th part of sequence: \", ratio.mean())\n",
    "\n",
    "ratios_df = pd.DataFrame(list(ratios_dict.items()), columns=['Segment', 'Mean Ratio'])\n",
    "\n",
    "\n",
    "ratios_df[['Nucleotide', 'Part']] = ratios_df['Segment'].str.split('_', expand=True)\n",
    "ratios_df['Part'] = ratios_df['Part'].astype(int)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for nucleotide in useful_nucleotides:\n",
    "    subset = ratios_df[ratios_df['Nucleotide'] == nucleotide]\n",
    "    plt.plot(subset['Part'], subset['Mean Ratio'], marker='o', label=nucleotide)\n",
    "\n",
    "plt.title('Mean Ratio of Nucleotides in Different Parts of Sequences')\n",
    "plt.xlabel('Part of Sequence')\n",
    "plt.ylabel('Mean Ratio')\n",
    "plt.legend(title='Nucleotide')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find common k-length sequences\n",
    "\n",
    "Uses sliding window on all sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "all_sequences = train_sequences['sequence'].to_list()\n",
    "\n",
    "k_sequences = {}\n",
    "\n",
    "for sequence in all_sequences:\n",
    "    for i in range(len(sequence) - k + 1):\n",
    "        if sequence[i:i + k] in k_sequences.keys():\n",
    "            k_sequences[sequence[i:i + k]] += 1\n",
    "        else:\n",
    "            k_sequences[sequence[i:i + k]] = 1\n",
    "\n",
    "num_most_popular = 5\n",
    "\n",
    "# get the ten most popular k-sequences\n",
    "most_popular_k_sequences = sorted(k_sequences.items(), key=lambda x: x[1], reverse=True)[:num_most_popular]\n",
    "print(f\"The {num_most_popular} most popular {k} length k-sequences are: \", most_popular_k_sequences)\n",
    "\n",
    "all_sequences_length = len(''.join(all_sequences))\n",
    "\n",
    "# for i in most_popular_k_sequences:\n",
    "#     print(f\"Ratio of {i[0]} in all sequences: \", i[1] / all_sequences_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the distribution of distances between consecutive points for each dim\n",
    "\n",
    "TODO Ensure correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = train_labels[['x_1', 'y_1', 'z_1']].dropna().to_numpy()\n",
    "distances = np.diff(distances, axis=0)\n",
    "distances = np.linalg.norm(distances, axis=1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    axs[i].hist(distances[:, i], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axs[i].set_title('X-axis Distances')\n",
    "    axs[i].set_xlabel('Distance')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "    axs[i].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the distribution of change in angle between consecutive points\n",
    "\n",
    "TODO Ensure correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_change_3d(p1: np.array, p2: np.array, p3: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Computes change in angle from p1 to p2 vs p3 in 3d space\n",
    "    \"\"\"\n",
    "\n",
    "    v1 = p2 - p1\n",
    "    v2 = p3 - p2\n",
    "    \n",
    "    v1_norm = np.linalg.norm(v1)\n",
    "    v2_norm = np.linalg.norm(v2)\n",
    "    \n",
    "    if v1_norm == 0 or v2_norm == 0:\n",
    "        raise ValueError(\"One of the vectors has zero length, cannot compute angle.\")\n",
    "    \n",
    "    v1 = v1 / v1_norm\n",
    "    v2 = v2 / v2_norm\n",
    "\n",
    "    dot_product = np.clip(np.dot(v1, v2), -1.0, 1.0)\n",
    "    \n",
    "    return np.degrees(np.arccos(dot_product))\n",
    "\n",
    "all_xyz = train_labels[['x_1', 'y_1', 'z_1']].dropna().to_numpy()\n",
    "\n",
    "differences = np.empty((len(all_xyz) - 2, 3))\n",
    "\n",
    "for i in range(len(all_xyz) - 2):\n",
    "    differences[i + 2, :] = angle_change_3d(all_xyz[i], all_xyz[i + 1], all_xyz[i + 2])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    axs[i].hist(differences[:, i], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axs[i].set_title('X-axis Delta Angles')\n",
    "    axs[i].set_xlabel('Angle (degrees)')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "    axs[i].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the densities of different models\n",
    "\n",
    "See if the small sequences are more dense than the big sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the labels into each target_id\n",
    "# Then, use all the points and put into numpy array\n",
    "# Calculate this density and yeah\n",
    "\n",
    "# plt.scatter sequence size vs. density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_labels.head(3))\n",
    "display(train_sequences.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Fasta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fasta(file_path):\n",
    "    \"\"\"\n",
    "    Displays the contents of a FASTA file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the FASTA file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                print(line, end='')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "# file_path = 'sequence.fasta'\n",
    "# display_fasta(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'stanford-rna-3d-folding/MSA/{sample_polymers[0]}.MSA.fasta'\n",
    "display_fasta(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
